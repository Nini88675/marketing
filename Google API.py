# -*- coding: utf-8 -*-
"""analyse video.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cbX20-RA44Ej2aDr2OFK8ezUB8VhYCl8
"""

!pip install yt-dlp moviepy SpeechRecognition google-cloud-videointelligence opencv-python-headless numpy scikit-learn tqdm

!apt-get update
!apt-get install -y ffmpeg

# ============================================================
# 1Ô∏è‚É£ Import des librairies
# ============================================================
import io, os, cv2, json, numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from google.cloud import videointelligence
import yt_dlp
from google.protobuf import json_format
import subprocess
import tempfile

# ============================================================
#  MODE DEBUG
# ============================================================
DEBUG = True

# ============================================================
# 2Ô∏è‚É£ Authentification Google Cloud (avec cl√© JSON)
# ============================================================
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "eloquent-walker-475913-h9-8b3f82a4480d.json"
print("‚úÖ Cl√© Google Cloud charg√©e.")

# ============================================================
#  URL
# ============================================================
urls = [
    "https://www.youtube.com/watch?v=guS6wULNixE",
    "https://www.youtube.com/watch?v=B0O_LeuKTJU",
    "https://www.youtube.com/watch?v=djG52oBOeeg",
    "https://www.youtube.com/watch?v=9cPxh2DikIA",
    "https://www.youtube.com/watch?v=ZbWKk_Kh1b4",
    "https://www.youtube.com/watch?v=IK0i48ffjnY"
]
os.makedirs("videos", exist_ok=True)
os.makedirs("results", exist_ok=True)

# ============================================================
#  V√©rification et conversion codec avec FFmpeg
# ============================================================
def check_ffmpeg():
    """V√©rifie que FFmpeg est install√©"""
    try:
        subprocess.run(["ffmpeg", "-version"],
                      stdout=subprocess.PIPE,
                      stderr=subprocess.PIPE,
                      check=True)
        return True
    except:
        return False

def convert_to_h264(input_path):
    """Convertit la vid√©o en H.264 (compatible OpenCV)"""
    output_path = input_path.replace(".mp4", "_h264.mp4")

    # Si d√©j√† converti, on skip
    if os.path.exists(output_path):
        print(f"‚úÖ Version H.264 existe d√©j√† : {output_path}")
        return output_path

    print(f"üîÑ Conversion en H.264 pour compatibilit√© OpenCV...")
    cmd = [
        "ffmpeg", "-i", input_path,
        "-c:v", "libx264",       # Codec H.264
        "-preset", "fast",       # Conversion rapide
        "-crf", "23",            # Qualit√© (18-28, 23 = bon compromis)
        "-c:a", "aac",           # Audio AAC
        "-movflags", "+faststart", # Optimisation streaming
        "-y",                    # Overwrite
        output_path
    ]

    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"‚úÖ Conversion r√©ussie : {output_path}")
        return output_path
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è Erreur de conversion : {e}")
        return input_path  # On retourne l'original en fallback

# ============================================================
# 4Ô∏è T√©l√©chargement YouTube avec codec H.264 forc√©
# ============================================================
def download_video(url):
    ydl_opts = {
        # ‚úÖ FIX : Forcer H.264 (AVC) au lieu de H.265 (HEVC)
        'format': 'bestvideo[vcodec^=avc1]+bestaudio[ext=m4a]/best[vcodec^=avc1]/best',
        'outtmpl': 'videos/%(id)s.%(ext)s',
        'merge_output_format': 'mp4',
        'quiet': False,
        'postprocessors': [{
            'key': 'FFmpegVideoConvertor',
            'preferedformat': 'mp4',
        }]
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)
        video_path = f"videos/{info['id']}.mp4"

        # V√©rification de la taille du fichier
        if os.path.exists(video_path) and os.path.getsize(video_path) > 1_000_000:
            print(f"‚úÖ Vid√©o t√©l√©charg√©e : {video_path}")

            # Test rapide de lecture OpenCV
            cap = cv2.VideoCapture(video_path)
            ret, frame = cap.read()
            cap.release()

            if not ret:
                print(f"‚ö†Ô∏è OpenCV ne peut pas lire la vid√©o, conversion n√©cessaire...")
                if check_ffmpeg():
                    video_path = convert_to_h264(video_path)
                else:
                    print("‚ùå FFmpeg non install√©. Installez-le avec: sudo apt-get install ffmpeg")
                    raise Exception("FFmpeg requis pour la conversion")

            return video_path
        else:
            raise Exception(f"[Erreur] Vid√©o vide ou non t√©l√©charg√©e : {video_path}")

# ============================================================
# 5Ô∏èAnalyse Google Cloud Video Intelligence
# ============================================================
def analyze_video(video_path):
    client = videointelligence.VideoIntelligenceServiceClient()
    features = [
        videointelligence.Feature.OBJECT_TRACKING,
        videointelligence.Feature.TEXT_DETECTION,
        videointelligence.Feature.LABEL_DETECTION,
        videointelligence.Feature.SHOT_CHANGE_DETECTION
    ]
    with io.open(video_path, "rb") as f:
        input_content = f.read()

    file_size_mb = len(input_content) / (1024 * 1024)
    print(f"‚è≥ Analyse de {video_path} ({file_size_mb:.1f} MB)...")

    operation = client.annotate_video(request={"features": features, "input_content": input_content})
    result = operation.result(timeout=600)
    print("‚úÖ Analyse termin√©e")

    # üîç DEBUG : V√©rifier ce que l'API retourne
    if DEBUG and result.annotation_results:
        ann = result.annotation_results[0]
        print(f"   üì¶ Objets d√©tect√©s : {len(ann.object_annotations) if ann.object_annotations else 0}")
        print(f"   üìù Textes d√©tect√©s : {len(ann.text_annotations) if ann.text_annotations else 0}")
        print(f"   üè∑Ô∏è Labels d√©tect√©s : {len(ann.segment_label_annotations) if ann.segment_label_annotations else 0}")

    return result.annotation_results[0]

# ============================================================
# 6Extraction de m√©triques marketing (AVEC FIX OPENCV)
# ============================================================
def compute_metrics(video_path, result):
    # ‚úÖ FIX : Utiliser le backend FFmpeg de OpenCV
    cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG)

    try:
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        if DEBUG:
            print(f"\nüé¨ Propri√©t√©s vid√©o :")
            print(f"   - Frames totales : {total_frames}")
            print(f"   - FPS : {fps}")
            print(f"   - R√©solution : {width}x{height}")

        # Protection contre division par z√©ro
        if fps == 0 or total_frames == 0:
            print(f"‚ö†Ô∏è Vid√©o invalide : fps={fps}, frames={total_frames}")
            return {
                "Burger_screen_ratio": 0.0,
                "Presence_of_promotional_text": False,
                "Color_intensity": 0.0,
                "Vegetable_objects_detected": [],
                "Time_to_logo_appearance": -1,
                "error": "Invalid video parameters"
            }

        duration = total_frames / fps
        if DEBUG:
            print(f"   - Dur√©e : {duration:.1f}s")

        # --- Burger_screen_ratio ---
        burger_time = 0
        burger_objects = []

        if result.object_annotations:
            for obj in result.object_annotations:
                desc = obj.entity.description.lower()
                # üîç DEBUG : Afficher tous les objets d√©tect√©s
                if DEBUG:
                    print(f"   üîé Objet trouv√© : '{desc}' ({len(obj.frames)} frames)")

                if desc in ["burger", "hamburger", "cheeseburger", "food"]:
                    burger_objects.append(desc)
                    for frame in obj.frames:
                        burger_time += 1 / fps

        burger_ratio = burger_time / duration if duration > 0 else 0

        if DEBUG:
            print(f"   üçî Burgers d√©tect√©s : {burger_objects}")
            print(f"   ‚è±Ô∏è Temps burger : {burger_time:.1f}s / {duration:.1f}s = {burger_ratio:.2%}")

        # --- Presence_of_promotional_text (OCR) ---
        promo_texts = ["buy", "new", "limited", "offer", "promo", "discount", "sale"]
        promo_detected = False
        found_texts = []

        if result.text_annotations:
            for text in result.text_annotations:
                if DEBUG:
                    print(f"   üìù Texte trouv√© : '{text.text}'")

                text_lower = text.text.lower()
                matching_words = [word for word in promo_texts if word in text_lower]
                if matching_words:
                    promo_detected = True
                    found_texts.extend(matching_words)

        if DEBUG and promo_detected:
            print(f"   üéØ Mots promotionnels trouv√©s : {set(found_texts)}")

        # --- Vegetable_objects_detected (NOUVEAU) ---
        vegetable_objects = []

        if result.object_annotations:
            for obj in result.object_annotations:
                desc = obj.entity.description.lower()
                vegetable_keywords = ["lettuce", "tomato", "onion", "pickle", "vegetable", "salad", "cucumber",
    "leaf", "greens", "spinach", "arugula", "kale", "herb", "basil",
    "parsley", "cilantro", "mint", "avocado", "pepper", "bell pepper",
    "chili", "jalapeno", "mushroom", "olive", "cabbage", "carrot"]

                if any(veg in desc for veg in vegetable_keywords):
                    vegetable_objects.append(desc)
                    if DEBUG:
                        print(f"   ü•¨ V√©g√©tal d√©tect√© : '{desc}'")

        if DEBUG:
            print(f"   ü•¨ V√©g√©taux d√©tect√©s : {vegetable_objects}")

        # --- Time_to_logo_appearance (NOUVEAU) ---
        logo_time = -1  # -1 = non d√©tect√©
        logo_keywords = ["logo", "brand", "mcdonald", "kfc", "burger king", "wendy", "subway","taco bell","jack in the box"]

        if result.object_annotations:
            for obj in result.object_annotations:
                desc = obj.entity.description.lower()
                if any(logo in desc for logo in logo_keywords):
                    if obj.frames:
                        first_frame_time = obj.frames[0].time_offset.seconds + obj.frames[0].time_offset.microseconds / 1e6
                        if logo_time == -1 or first_frame_time < logo_time:
                            logo_time = first_frame_time
                            if DEBUG:
                                print(f"   üè∑Ô∏è Logo d√©tect√© : '{desc}' √† {logo_time:.1f}s")

        if result.text_annotations:
            for text in result.text_annotations:
                text_lower = text.text.lower()
                if any(logo in text_lower for logo in logo_keywords):
                    if text.segments:
                        first_segment_time = text.segments[0].segment.start_time_offset.seconds + text.segments[0].segment.start_time_offset.microseconds / 1e6
                        if logo_time == -1 or first_segment_time < logo_time:
                            logo_time = first_segment_time
                            if DEBUG:
                                print(f"   üè∑Ô∏è Texte de logo d√©tect√© : '{text.text}' √† {logo_time:.1f}s")

        # --- Color_intensity (saturation moyenne) ---
        # ‚úÖ FIX : √âchantillonnage plus intelligent
        num_samples = min(20, total_frames // fps)  # Max 20 √©chantillons ou 1 par seconde
        if num_samples == 0:
            num_samples = 1

        step = max(1, total_frames // num_samples)
        saturations = []
        frames_processed = 0

        if DEBUG:
            print(f"   üé® Extraction couleurs ({num_samples} √©chantillons, step={step})...")

        for i in range(num_samples):
            frame_idx = min(i * step, total_frames - 1)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()

            if not ret:
                if DEBUG:
                    print(f"   ‚ö†Ô∏è Frame {frame_idx} non lue (ret={ret})")
                continue

            if frame is None or frame.size == 0:
                if DEBUG:
                    print(f"   ‚ö†Ô∏è Frame {frame_idx} vide")
                continue

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            saturation = hsv[:, :, 1].mean() / 255.0
            saturations.append(saturation)
            frames_processed += 1

        color_intensity = float(np.mean(saturations)) if saturations else 0.0

        if DEBUG:
            print(f"   ‚úÖ Frames analys√©es : {frames_processed}/{num_samples}")
            if saturations:
                print(f"   üìä Saturations : min={min(saturations):.3f}, max={max(saturations):.3f}, mean={color_intensity:.3f}")
            else:
                print(f"   ‚ö†Ô∏è Aucune saturation calcul√©e - probl√®me de lecture vid√©o")

        return {
            "Burger_screen_ratio": round(burger_ratio, 3),
            "Presence_of_promotional_text": promo_detected,
            "Color_intensity": round(color_intensity, 3),
            "Vegetable_objects_detected": vegetable_objects,
            "Time_to_logo_appearance": round(logo_time, 1) if logo_time != -1 else -1
        }

    finally:
        cap.release()

# ============================================================
# 7Ô∏è‚É£ Boucle principale avec cache et gestion des erreurs
# ============================================================
results = {}

for url in tqdm(urls, desc="Analyse des vid√©os"):
    print(f"\n{'='*60}")
    print(f"üé• Traitement : {url}")
    print(f"{'='*60}")

    try:
        video_path = download_video(url)
    except Exception as e:
        print(f"[Erreur] T√©l√©chargement √©chou√© : {e}")
        continue

    video_id = os.path.splitext(os.path.basename(video_path))[0].replace("_h264", "")
    json_path = f"results/{video_id}.json"

    # Gestion des JSON existants
    if os.path.exists(json_path):
        print(f"‚ö° R√©sultat existant trouv√© pour {video_id}, rechargement‚Ä¶")
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if not content.strip():
                    raise ValueError("Fichier JSON vide")
                data = json.loads(content)

            if not data:
                raise ValueError("JSON vide apr√®s parsing")

            # ‚úÖ CORRECTION : Utiliser MessageToDict au lieu de to_dict()
            from google.protobuf.json_format import MessageToDict
            result_obj = videointelligence.VideoAnnotationResults()
            json_format.Parse(json.dumps(data), result_obj)
            res = result_obj
            print(f"‚úÖ JSON recharg√© avec succ√®s")

        except (json.JSONDecodeError, ValueError) as e:
            print(f"‚ö†Ô∏è JSON corrompu ou vide ({e}), nouvelle analyse...")
            os.remove(json_path)

            try:
                res = analyze_video(video_path)
                with open(json_path, "w", encoding='utf-8') as f:
                    # ‚úÖ CORRECTION : Utiliser MessageToDict au lieu de to_dict()
                    from google.protobuf.json_format import MessageToDict
                    result_dict = MessageToDict(res._pb)
                    json.dump(result_dict, f, indent=2, ensure_ascii=False)

                file_size = os.path.getsize(json_path)
                print(f"üíæ Nouveau JSON sauvegard√© : {json_path} ({file_size} bytes)")

            except Exception as e2:
                print(f"[Erreur] Analyse √©chou√©e pour {video_id} : {e2}")
                continue
    else:
        try:
            res = analyze_video(video_path)

            try:
                with open(json_path, "w", encoding='utf-8') as f:
                    # ‚úÖ CORRECTION : Utiliser MessageToDict au lieu de to_dict()
                    from google.protobuf.json_format import MessageToDict
                    result_dict = MessageToDict(res._pb)
                    json.dump(result_dict, f, indent=2, ensure_ascii=False)

                file_size = os.path.getsize(json_path)
                print(f"üíæ R√©sultat sauvegard√© : {json_path} ({file_size} bytes)")

            except Exception as save_error:
                print(f"‚ö†Ô∏è Erreur lors de la sauvegarde JSON : {save_error}")

        except Exception as e:
            print(f"[Erreur] Analyse √©chou√©e pour {video_id} : {e}")
            continue

    # Calcul des m√©triques
    try:
        metrics = compute_metrics(video_path, res)
        results[url] = metrics
    except Exception as e:
        print(f"[Erreur] Calcul de m√©triques √©chou√© pour {video_id} : {e}")
        import traceback
        traceback.print_exc()
        continue

# ============================================================
# 8Ô∏è‚É£ R√©sultats et visualisation
# ============================================================
print("\n" + "="*60)
print("=== üìä R√©sultats comparatifs ===")
print("="*60)

for u, m in results.items():
    print(f"\nüé• {u}")
    for k, v in m.items():
        print(f"   - {k}: {v}")

if results:
    plt.figure(figsize=(12, 6))
    x = np.arange(len(results))
    bars = [m["Burger_screen_ratio"] for m in results.values()]
    colors = ['#FF6B6B' if b > 0 else '#95A5A6' for b in bars]

    plt.bar(x, bars, color=colors)
    plt.xticks(x, [f"Vid√©o {i+1}" for i in range(len(results))], rotation=45)
    plt.ylabel("Burger Screen Ratio")
    plt.title("Importance visuelle du burger par vid√©o")
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig("results/burger_comparison.png", dpi=150)
    print("\nüìà Graphique sauvegard√© : results/burger_comparison.png")
    plt.show()
else:
    print("‚ö†Ô∏è Aucun r√©sultat √† afficher.")

print(f"\n‚úÖ Analyse termin√©e ! {len(results)}/{len(urls)} vid√©os trait√©es.")

import pandas as pd
data = {
    "id": [
        "guS6wULNixE",
        "B0O_LeuKTJU",
        "djG52oBOeeg",
        "9cPxh2DikIA",
        "ZbWKk_Kh1b4",
        "IK0i48ffjnY"
    ],
    "Burger_screen_ratio": [0.038, 0.003, 0.008, 0.24, 0.444, 0.531],
    "Presence_of_promotional_text": [False, False, True, False, False, False],
    "Color_intensity": [0.449, 0.253, 0.368, 0.476, 0.431, 0.285],
    "Time_to_logo_appearance": [3.7, 6.0, 0.0, 24.4, 0.4, -1]
}

df = pd.DataFrame(data)
df